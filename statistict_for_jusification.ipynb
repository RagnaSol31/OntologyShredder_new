{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44b7f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rdflib pandas\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from rdflib import Graph, RDF, RDFS, OWL, BNode\n",
    "from rdflib.collection import Collection\n",
    "\n",
    "from collections import defaultdict, Counter, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4612e43e",
   "metadata": {},
   "source": [
    "## OWL Konzepte Vergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eddb51",
   "metadata": {},
   "source": [
    "Z√§hlt f√ºr alle 50 BioPortal Ontologien wie oft ein Konzept auftritt und bestimmt unteranderem den Durchschnitt und Median prop Konstrukt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad057c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Konstrukte\n",
    "# üîß Pfade\n",
    "ONT_DIR = r\"C:\\Users\\ilove\\OneDrive\\Uni\\Master - Philipps Uni\\Master Thesis\\Ontologien\\Zum Testen von Verteilungen von Konzepten\\Bio Portal\\nochmal\"\n",
    "OUT_CSV = \"Bio_Portal_ontology_property_counts_full_7.csv\"\n",
    "OUT_SUMMARY = \"Bio_Portal_construct_summary_7.csv\"\n",
    "\n",
    "# --- 1) Definition aller zu z√§hlenden Konstrukte ---\n",
    "\n",
    "# a) Dinge, die √ºber rdf:type gez√§hlt werden (Klassen/Konstrukte + Property-Eigenschaften!)\n",
    "#    Manche OWL2-Varianten haben alternative Klassennamen (z. B. SymmetricObjectProperty).\n",
    "TYPE_MULTI = {\n",
    "    # Klassen-Axiome (TBox)\n",
    "    \"owl:Class\": [OWL.Class],\n",
    "    \"rdfs:Class\":[RDFS.Class],\n",
    "    \"owl:AllDisjointClasses\": [OWL.AllDisjointClasses],\n",
    "    \"owl:DeprecatedClass\": [OWL.DeprecatedClass],\n",
    "\n",
    "    # Individuen-Axiome (ABox)\n",
    "    \"owl:AllDifferent\": [OWL.AllDifferent],\n",
    "    \"owl:NegativePropertyAssertion\": [OWL.NegativePropertyAssertion],\n",
    "\n",
    "    # Datatype Handling\n",
    "    \"rdfs:Datatype\": [RDFS.Datatype],\n",
    "\n",
    "    # RDFS Konstrukte (als Typ)\n",
    "    \"rdf:List\": [RDF.List],\n",
    "\n",
    "    # Property-Typen (separat reporten; NICHT in SUMME einbeziehen)\n",
    "    \"owl:ObjectProperty\": [OWL.ObjectProperty],\n",
    "    \"owl:DatatypeProperty\": [OWL.DatatypeProperty],\n",
    "    \"owl:AnnotationProperty\": [OWL.AnnotationProperty],\n",
    "    \"owl:DeprecatedProperty\": [OWL.DeprecatedProperty],\n",
    "    \"rdf:Property\": [RDF.Property],\n",
    "\n",
    "    # OWL 2: Axiom-Objekt als Klasse\n",
    "    \"owl:AllDisjointProperties\": [OWL.AllDisjointProperties],\n",
    "\n",
    "    # üëâ Property-Eigenschaften (als Typ!) ‚Äì hier korrekt via rdf:type:\n",
    "    \"owl:FunctionalProperty\": [OWL.FunctionalProperty],\n",
    "    \"owl:InverseFunctionalProperty\": [OWL.InverseFunctionalProperty],\n",
    "    \"owl:SymmetricProperty\": [OWL.SymmetricProperty],\n",
    "    \"owl:AsymmetricProperty\": [OWL.AsymmetricProperty],\n",
    "    \"owl:TransitiveProperty\": [OWL.TransitiveProperty],\n",
    "    \"owl:ReflexiveProperty\": [OWL.ReflexiveProperty],\n",
    "    \"owl:IrreflexiveProperty\": [OWL.IrreflexiveProperty],\n",
    "}\n",
    "\n",
    "# b) Dinge, die als Pr√§dikat auftreten (Triple-Mittelteil)\n",
    "PREDICATES = {\n",
    "    # Klassen-Axiome (TBox)\n",
    "    \"rdfs:subClassOf\": RDFS.subClassOf,\n",
    "    \"owl:equivalentClass\": OWL.equivalentClass,\n",
    "    \"owl:disjointWith\": OWL.disjointWith,\n",
    "    \"owl:disjointUnionOf\": OWL.disjointUnionOf,\n",
    "    \"owl:hasKey\": OWL.hasKey,\n",
    "\n",
    "    # Klassen-Konstruktoren\n",
    "    \"owl:intersectionOf\": OWL.intersectionOf,\n",
    "    \"owl:unionOf\": OWL.unionOf,\n",
    "    \"owl:complementOf\": OWL.complementOf,\n",
    "    \"owl:oneOf\": OWL.oneOf,  # EnumeratedClass\n",
    "\n",
    "    # Property Restrictions\n",
    "    \"owl:someValuesFrom\": OWL.someValuesFrom,\n",
    "    \"owl:allValuesFrom\": OWL.allValuesFrom,\n",
    "    \"owl:hasValue\": OWL.hasValue,\n",
    "    \"owl:minCardinality\": OWL.minCardinality,\n",
    "    \"owl:maxCardinality\": OWL.maxCardinality,\n",
    "    \"owl:cardinality\": OWL.cardinality,\n",
    "    \"owl:minQualifiedCardinality\": OWL.minQualifiedCardinality,\n",
    "    \"owl:maxQualifiedCardinality\": OWL.maxQualifiedCardinality,\n",
    "    \"owl:qualifiedCardinality\": OWL.qualifiedCardinality,\n",
    "    \"owl:hasSelf\": OWL.hasSelf,\n",
    "\n",
    "    # Property-Axiome (Pr√§dikate)\n",
    "    \"rdfs:subPropertyOf\": RDFS.subPropertyOf,\n",
    "    \"rdfs:domain\": RDFS.domain,\n",
    "    \"rdfs:range\": RDFS.range,\n",
    "    \"owl:propertyDisjointWith\": OWL.propertyDisjointWith,\n",
    "    \"owl:inverseOf\": OWL.inverseOf,\n",
    "    \"owl:equivalentProperty\": OWL.equivalentProperty,\n",
    "    \"owl:propertyChainAxiom\": OWL.propertyChainAxiom,\n",
    "\n",
    "    # ABox\n",
    "    \"owl:differentFrom\": OWL.differentFrom,\n",
    "    \"owl:sameAs\": OWL.sameAs,\n",
    "\n",
    "    # Datatype Handling (Pr√§dikate)\n",
    "    \"owl:onDatatype\": OWL.onDatatype,\n",
    "    \"owl:withRestrictions\": OWL.withRestrictions,\n",
    "\n",
    "    # RDFS (Pr√§dikate)\n",
    "    \"rdf:type\": RDF.type,\n",
    "    \"rdfs:member\": RDFS.member,\n",
    "    \"rdfs:label\": RDFS.label,\n",
    "    \"rdfs:comment\": RDFS.comment,\n",
    "    \"rdfs:seeAlso\": RDFS.seeAlso,\n",
    "    \"rdfs:isDefinedBy\": RDFS.isDefinedBy,\n",
    "\n",
    "    # RDF List Pr√§dikate\n",
    "    \"rdf:first\": RDF.first,\n",
    "    \"rdf:rest\": RDF.rest,\n",
    "}\n",
    "# rdf:nil ist eine Ressource ‚Äì wir z√§hlen Vorkommen als Objekt separat\n",
    "COUNT_RDF_NIL = True\n",
    "\n",
    "# Welche Spalten NICHT in die SUMME eingehen (nur reporten)\n",
    "EXCLUDE_FROM_SUM = {\n",
    "    \"owl:ObjectProperty\",\n",
    "    \"owl:DatatypeProperty\",\n",
    "    \"owl:AnnotationProperty\",\n",
    "    \"rdf:Property\",\n",
    "    \"owl:Class\",\n",
    "    \"rdfs:Class\"\n",
    "}\n",
    "\n",
    "EXTS = (\".owl\", \".ttl\", \".rdf\")\n",
    "\n",
    "def count_in_graph(g: Graph) -> dict:\n",
    "    counts = {}\n",
    "\n",
    "    # rdf:type-basierte Z√§hlungen (inkl. Property-Eigenschaften als Typ!)\n",
    "    for label, class_list in TYPE_MULTI.items():\n",
    "        total = 0\n",
    "        for cls in class_list:\n",
    "            total += sum(1 for _ in g.subjects(RDF.type, cls))\n",
    "        counts[label] = total\n",
    "\n",
    "    # Pr√§dikat-basierte Z√§hlungen\n",
    "    for label, pred in PREDICATES.items():\n",
    "        counts[label] = sum(1 for _ in g.triples((None, pred, None)))\n",
    "\n",
    "    # rdf:nil (als Objekt)\n",
    "    if COUNT_RDF_NIL:\n",
    "        counts[\"rdf:nil (as object)\"] = sum(1 for _ in g.triples((None, None, RDF.nil)))\n",
    "\n",
    "    # SUMME (ohne die reinen Property-Typen)\n",
    "    sum_keys = [k for k in counts.keys() if k not in EXCLUDE_FROM_SUM]\n",
    "    counts[\"SUMME\"] = sum(counts[k] for k in sum_keys if k != \"SUMME\")\n",
    "\n",
    "    return counts\n",
    "\n",
    "# --- 2) Dateien z√§hlen & CSV mit allen Rohzahlen schreiben ---\n",
    "rows = []\n",
    "idx = 1\n",
    "for fname in sorted(os.listdir(ONT_DIR)):\n",
    "    print(f\"{idx}. {fname}\")\n",
    "    if not fname.lower().endswith(EXTS):\n",
    "        idx += 1\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(ONT_DIR, fname)\n",
    "    try:\n",
    "        g = Graph()\n",
    "        g.parse(path)\n",
    "        c = count_in_graph(g)\n",
    "    except Exception as e:\n",
    "        # bei Fehlern alle Keys auf 0\n",
    "        zero_keys = (\n",
    "            list(TYPE_MULTI.keys())\n",
    "            + list(PREDICATES.keys())\n",
    "            + ([\"rdf:nil (as object)\"] if COUNT_RDF_NIL else [])\n",
    "            + [\"SUMME\"]\n",
    "        )\n",
    "        c = {k: 0 for k in zero_keys}\n",
    "        c[\"_error\"] = str(e)\n",
    "\n",
    "    row = {\"file\": fname, **c}\n",
    "    print(f\"    {row}\")\n",
    "    rows.append(row)\n",
    "    idx += 1\n",
    "\n",
    "# Spaltenreihenfolge\n",
    "columns = (\n",
    "    [\"file\"]\n",
    "    + list(TYPE_MULTI.keys())\n",
    "    + list(PREDICATES.keys())\n",
    "    + ([\"rdf:nil (as object)\"] if COUNT_RDF_NIL else [])\n",
    "    + [\"SUMME\"]\n",
    ")\n",
    "if any(\"_error\" in r for r in rows):\n",
    "    columns += [\"_error\"]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"‚úÖ Rohzahlen gespeichert: {OUT_CSV}\")\n",
    "\n",
    "# --- 3) Auswertungstabelle (Summe, #Ontologien, %Ontologien, √ò, Median, Max) ---\n",
    "\n",
    "# __TOTAL__ Zeilen gibt's hier nicht; wir nehmen direkt df\n",
    "df = pd.read_csv(OUT_CSV)\n",
    "N = len(df)\n",
    "\n",
    "# Alle Konstruktspalten f√ºr die Auswertung:\n",
    "# (Alles au√üer Datei-Name, _error und SUMME; Property-Typen bleiben drin ‚Äì werden aber nicht zusammengez√§hlt,\n",
    "#  hier machen wir eine per-Konstrukt-Auswertung, also d√ºrfen sie erscheinen.)\n",
    "construct_cols = [c for c in df.columns if c not in (\"file\", \"_error\", \"SUMME\")]\n",
    "\n",
    "summary_rows = []\n",
    "for col in construct_cols:\n",
    "    vals = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "    total = int(vals.sum())\n",
    "    ont_count = int((vals > 0).sum())\n",
    "    percent = (ont_count / N * 100) if N else 0\n",
    "\n",
    "    nonzero_vals = sorted(vals[vals > 0].tolist())\n",
    "    if ont_count > 0:\n",
    "        avg = float(vals[vals > 0].mean())\n",
    "        med = float(vals[vals > 0].median())\n",
    "        minv = min(nonzero_vals)\n",
    "        avg_0 = float(vals[vals >= 0].mean())\n",
    "        med_0 = float(vals[vals >= 0].median())\n",
    "    else:\n",
    "        avg = med = minv = avg_0 = med_0 = 0.0\n",
    "        \n",
    "    maxv = int(vals.max()) if len(vals) else 0\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"Construct\": col,\n",
    "        \"Summe\": total,\n",
    "        \"#Ontologien\": ont_count,\n",
    "        \"%Ontologien\": round(percent, 1),\n",
    "        \"√ò pro Ontologie (ohne 0)\": round(avg, 2),\n",
    "        \"√ò pro Ontologie (mit 0)\": round(avg_0, 2),\n",
    "        \"Median (ohne 0)\": med,\n",
    "        \"Median (mit 0)\": med_0,\n",
    "        \"Min (>0)\": minv,\n",
    "        \"Max\": maxv,\n",
    "        \"Werte (f√ºr Median ohne 0)\": nonzero_vals,  # hier alle Werte explizit\n",
    "        \"Werte (f√ºr Median mit 0)\": sorted(vals.tolist())\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(by=[\"Summe\", \"#Ontologien\"], ascending=False)\n",
    "summary_df.to_csv(OUT_SUMMARY, index=False)\n",
    "\n",
    "print(f\"‚úÖ Auswertung gespeichert: {OUT_SUMMARY}\")\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba6a5c",
   "metadata": {},
   "source": [
    "Z√§hlt f√ºr die 19 BioPortal Ontologien die PropertyChainAxiome haben, aus wie vielen Elementen diese jeweils bestehen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PropertyChainAxiom\n",
    "# üîß Pfade\n",
    "ONT_DIR = r\"C:\\Users\\ilove\\OneDrive\\Uni\\Master - Philipps Uni\\Master Thesis\\Ontologien\\Zum Testen von Verteilungen von Konzepten\\Bio Portal\\nochmal\"\n",
    "OUT_CSV = \"Bio_Portal_ontology_construct_depth_count3.csv\"\n",
    "\n",
    "# b) Dinge, die als Pr√§dikat auftreten (Triple-Mittelteil)\n",
    "PREDICATES = {\n",
    "    \"owl:propertyChainAxiom\": OWL.propertyChainAxiom,\n",
    "}\n",
    "\n",
    "EXTS = (\".owl\", \".ttl\", \".rdf\")\n",
    "\n",
    "def count_in_graph(g: Graph) -> dict:\n",
    "    counts = {}\n",
    "\n",
    "    for label, pred in PREDICATES.items():\n",
    "        results = []\n",
    "        for super_prop in g.subjects(OWL.propertyChainAxiom, None):\n",
    "            head = g.value(super_prop, OWL.propertyChainAxiom)\n",
    "            if head is None:\n",
    "                continue\n",
    "\n",
    "            length = 0\n",
    "            for item in Collection(g, head):\n",
    "                if isinstance(item, BNode):\n",
    "                    if isinstance(item, BNode) and g.value(item, OWL.inverseOf) is not None:\n",
    "                        # inverse Property Expression ‚Üí z√§hlt als 1\n",
    "                        length += 1\n",
    "                    elif isinstance(item, BNode) and g.value(item, OWL.inverseOf) is not None:\n",
    "                        # ungew√∂hnlich, aber falls vorhanden: Liste innerhalb der Liste flatten\n",
    "                        length += sum(1 for _ in Collection(g, item))\n",
    "                    else:\n",
    "                        # unbekannter BNode ‚Üí konservativ als 1 z√§hlen\n",
    "                        length += 1\n",
    "                else:\n",
    "                    # normale URI einer Objekt-Property\n",
    "                    length += 1\n",
    "\n",
    "            results.append(length)\n",
    "        length = dict(Counter(results))\n",
    "        max_length = max(results) if results else 0\n",
    "    \n",
    "        # print(list(Collection(g, triples)))\n",
    "        counts[label] = sum(1 for _ in g.triples((None, pred, None)))\n",
    "        counts[\"maxLength\"] = max_length\n",
    "        counts[\"length\"] = length\n",
    "\n",
    "\n",
    "    return counts\n",
    "\n",
    "# --- 2) Dateien z√§hlen & CSV mit allen Rohzahlen schreiben ---\n",
    "rows = []\n",
    "idx = 1\n",
    "for fname in sorted(os.listdir(ONT_DIR)):\n",
    "    print(f\"{idx}. {fname}\")\n",
    "    if not fname.lower().endswith(EXTS):\n",
    "        idx += 1\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(ONT_DIR, fname)\n",
    "    try:\n",
    "        g = Graph()\n",
    "        g.parse(path)\n",
    "        c = count_in_graph(g)\n",
    "    except Exception as e:\n",
    "        # bei Fehlern alle Keys auf 0\n",
    "        zero_keys = (\n",
    "\n",
    "            list(PREDICATES.keys())\n",
    "\n",
    "        )\n",
    "        c = {k: 0 for k in zero_keys}\n",
    "        c[\"_error\"] = str(e)\n",
    "\n",
    "    row = {\"file\": fname, **c}\n",
    "    print(f\"    {row}\")\n",
    "    rows.append(row)\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "# Bekannte Spalten zuerst\n",
    "known_cols = [\"file\"] + list(PREDICATES.keys())\n",
    "\n",
    "# Alle Keys einsammeln, die in rows vorkommen (inkl. max length etc.)\n",
    "all_keys = set()\n",
    "for r in rows:\n",
    "    all_keys.update(r.keys())\n",
    "\n",
    "# Extras = alles, was nicht schon in known_cols steckt\n",
    "extra_cols = [k for k in all_keys if k not in known_cols]\n",
    "\n",
    "# Falls du trotzdem \"_error\" am Ende haben willst:\n",
    "if \"_error\" in extra_cols:\n",
    "    extra_cols.remove(\"_error\")\n",
    "    extra_cols = extra_cols + [\"_error\"]\n",
    "\n",
    "# Finale Spaltenreihenfolge\n",
    "columns = known_cols + sorted(extra_cols)\n",
    "\n",
    "# DataFrame bauen und Spalten erzwingen\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.reindex(columns=columns)\n",
    "\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"‚úÖ Rohzahlen gespeichert: {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89fb25a",
   "metadata": {},
   "source": [
    "Z√§hlt f√ºr alle 50 BioPortal Ontologien wie h√§ufig f√ºr Proeprties die Konstrukt-Kombinationen Inverse + subProeprty, Inverse + Superproperty und Inverse + √Ñquivalente Property auftreten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53cca701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Allergidoc.rdf\n",
      "2 ATC_with_imports.rdf\n",
      "3 bao_complete_with_imports.rdf\n",
      "4 bcio.owl\n",
      "5 bervo.owl\n",
      "6 BMONT.owl\n",
      "7 BTO_with_imports.rdf\n",
      "8 CDMOnto.owl\n",
      "9 cheminf_with_imports.rdf\n",
      "10 cl.owl\n",
      "11 clo_merged.owl\n",
      "12 cob.owl\n",
      "13 COPPER.owl\n",
      "14 creno_with_imports.rdf\n",
      "15 CTCAE_5.0.owl\n",
      "16 dcm_with_imports.rdf\n",
      "17 DMDSONT.rdf\n",
      "18 doid_with_imports.rdf\n",
      "19 EDAM.owl\n",
      "20 envo.owl\n",
      "21 GAMUTS.owl\n",
      "22 gbol-ontology.ttl\n",
      "23 hspo_with_imports.rdf\n",
      "24 ICD10CM_with_imports.rdf\n",
      "25 ICD9CM_with_imports.rdf\n",
      "26 meo.v.1.0.ttl\n",
      "27 mwo.owl\n",
      "28 namo.owl.ttl\n",
      "29 ncro_with_imports.owl\n",
      "30 nochmal\n",
      "31 O3_20250709.owl\n",
      "32 oae_merged.owl\n",
      "33 oba.owl\n",
      "34 obi.owl\n",
      "35 OBOREL.owl\n",
      "36 odfa.owl\n",
      "37 OMIM_with_imports.rdf\n",
      "38 Ontos mit PropertyChainAxiom\n",
      "39 ordo_orphanet.owl\n",
      "40 pato.owl\n",
      "41 phases.owl\n",
      "42 plantso.owl\n",
      "43 RXNORM_with_imports.rdf\n",
      "44 SCO_with_imports.rdf\n",
      "45 sio-release.owl\n",
      "46 sleep.rdf\n",
      "47 slso.owl\n",
      "48 SNMI_with_imports.rdf\n",
      "49 ssbd_v20250512.ttl\n",
      "50 tara-acupoints-inferred.rdf\n",
      "51 uberon.owl\n",
      "52 VANDF_with_imports.rdf\n",
      "53 without_imports\n",
      "‚úÖ Rohzahlen gespeichert: Bio_Portal_ontology_inverse_combinations_counts_full3.csv\n",
      "‚úÖ Auswertung gespeichert: Bio_Portal_ontology_inverse_combinations_counts_summary3.csv\n",
      "\n",
      "Zusammenfassung:\n",
      "                     Construct  Summe  #Ontologien  %Ontologien  \\\n",
      "3  functionalProperty+inverse     69           20         40.0   \n",
      "0         subProperty+inverse      0            0          0.0   \n",
      "1       superProperty+inverse      0            0          0.0   \n",
      "2  equivalentProperty+inverse      0            0          0.0   \n",
      "\n",
      "   √ò pro Ontologie (ohne 0)  √ò pro Ontologie (mit 0)  Median (ohne 0)  \\\n",
      "3                      3.45                     1.38              1.5   \n",
      "0                      0.00                     0.00              0.0   \n",
      "1                      0.00                     0.00              0.0   \n",
      "2                      0.00                     0.00              0.0   \n",
      "\n",
      "   Median (mit 0)  Min (> 0)  Max  \\\n",
      "3             0.0        1.0   26   \n",
      "0             0.0        0.0    0   \n",
      "1             0.0        0.0    0   \n",
      "2             0.0        0.0    0   \n",
      "\n",
      "                                         Werte (> 0)  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, ...  \n",
      "0                                                 []  \n",
      "1                                                 []  \n",
      "2                                                 []  \n"
     ]
    }
   ],
   "source": [
    "# InverseOf + Sub/SuperPropertyOf und EquivalentProperty\n",
    "def count_patterns(g):\n",
    "    sub_inv, super_inv, equiv_inv, func_inv = 0, 0, 0, 0\n",
    "\n",
    "    # --- Fall 1+2: Direkt modelliert (gleiches Subjekt) ---\n",
    "    inverses = {x for s, p, o in g.triples((None, OWL.inverseOf, None)) for x in (s, o)}\n",
    "    for s in inverses:\n",
    "        # if (s, RDFS.subPropertyOf, None) in g:\n",
    "        #     sub_inv += 1\n",
    "        # if (None, RDFS.subPropertyOf, s) in g:\n",
    "        #     super_inv += 1\n",
    "        # if (s, OWL.equivalentProperty, None) in g or (None, OWL.equivalentProperty, s) in g:\n",
    "        #     equiv_inv += 1\n",
    "        if (s, RDF.type, OWL.FunctionalProperty) in g:\n",
    "            func_inv +=1\n",
    "\n",
    "    # # --- Fall 3: BNode-Konstrukte ---\n",
    "    # for s, _, o in g.triples((None, RDFS.subPropertyOf, None)):\n",
    "    #     if isinstance(o, BNode) and (o, OWL.inverseOf, None) in g:\n",
    "    #         sub_inv += 1\n",
    "    # for s, _, o in g.triples((None, OWL.equivalentProperty, None)):\n",
    "    #     if isinstance(o, BNode) and (o, OWL.inverseOf, None) in g:\n",
    "    #         equiv_inv += 1\n",
    "\n",
    "    return sub_inv, super_inv, equiv_inv, func_inv\n",
    "\n",
    "# --- Lauf √ºber alle Ontologien ---\n",
    "ONT_DIR = r\"C:\\Users\\ilove\\OneDrive\\Uni\\Master - Philipps Uni\\Master Thesis\\Ontologien\\Zum Testen von Verteilungen von Konzepten\\Bio Portal\"\n",
    "OUT_CSV = \"Bio_Portal_ontology_inverse_combinations_counts_full3.csv\"\n",
    "OUT_SUMMARY = \"Bio_Portal_ontology_inverse_combinations_counts_summary3.csv\"\n",
    "\n",
    "results = []\n",
    "count = 1\n",
    "for fname in os.listdir(ONT_DIR):\n",
    "    print(count, fname)\n",
    "    count += 1\n",
    "    if not fname.endswith((\".ttl\", \".rdf\", \".owl\")):\n",
    "        continue\n",
    "    path = os.path.join(ONT_DIR, fname)\n",
    "    g = Graph()\n",
    "    try:\n",
    "        g.parse(path)\n",
    "        sub_inv, super_inv, equiv_inv, func_inv = count_patterns(g)\n",
    "    except Exception as e:\n",
    "        sub_inv, equiv_inv = 0, 0\n",
    "    results.append({\n",
    "        \"file\": fname,\n",
    "        \"subProperty+inverse\": sub_inv,\n",
    "        \"superProperty+inverse\": super_inv,\n",
    "        \"equivalentProperty+inverse\": equiv_inv,\n",
    "        \"functionalProperty+inverse\": func_inv\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"‚úÖ Rohzahlen gespeichert: {OUT_CSV}\")\n",
    "\n",
    "# --- Statistik berechnen ---\n",
    "df = pd.read_csv(OUT_CSV)\n",
    "N = len(df)\n",
    "\n",
    "construct_cols = [c for c in df.columns if c not in (\"file\", \"total\")]\n",
    "\n",
    "summary_rows = []\n",
    "for col in construct_cols:\n",
    "    vals = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "    total = int(vals.sum())\n",
    "    ont_count = int((vals > 0).sum())\n",
    "    percent = (ont_count / N * 100) if N else 0\n",
    "\n",
    "    nonzero_vals = sorted(vals[vals > 0].tolist())\n",
    "    if ont_count > 0:\n",
    "        avg = float(vals[vals > 0].mean())\n",
    "        med = float(vals[vals > 0].median())\n",
    "        minv = min(nonzero_vals)\n",
    "        avg_0 = float(vals[vals >= 0].mean())\n",
    "        med_0 = float(vals[vals >= 0].median())\n",
    "    else:\n",
    "        avg = med = minv = avg_0 = med_0 = 0.0\n",
    "        \n",
    "    maxv = int(vals.max()) if len(vals) else 0\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"Construct\": col,\n",
    "        \"Summe\": total,\n",
    "        \"#Ontologien\": ont_count,\n",
    "        \"%Ontologien\": round(percent, 1),\n",
    "        \"√ò pro Ontologie (ohne 0)\": round(avg, 2),\n",
    "        \"√ò pro Ontologie (mit 0)\": round(avg_0, 2),\n",
    "        \"Median (ohne 0)\": med,\n",
    "        \"Median (mit 0)\": med_0,\n",
    "        \"Min (> 0)\": minv,\n",
    "        \"Max\": maxv,\n",
    "        \"Werte (> 0)\": nonzero_vals,  # hier alle Werte explizit\n",
    "        # \"Werte (f√ºr Median mit 0)\": sorted(vals.tolist())\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(by=[\"Summe\", \"#Ontologien\"], ascending=False)\n",
    "summary_df.to_csv(OUT_SUMMARY, index=False)\n",
    "\n",
    "print(f\"‚úÖ Auswertung gespeichert: {OUT_SUMMARY}\")\n",
    "print(\"\\nZusammenfassung:\\n\", summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a39ab",
   "metadata": {},
   "source": [
    "Z√§hlt f√ºr die 50 BioPortal Ontologien wie oft Kombinationen von Property-Eigenschaften auftreten.\\\n",
    "Es werden nur min einmal gefundene Eigenschaftskombis in die csv aufgenommen. D.h. alle nicht in der csv aufgef√ºhrten Kombis kommen in den 50 Ontologien nicht einmal vor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a01b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ATC_with_imports.rdf\n",
      "2. Allergidoc.rdf\n",
      "3. BMONT.owl\n",
      "4. BTO_with_imports.rdf\n",
      "5. CDMOnto.owl\n",
      "6. COPPER.owl\n",
      "7. CTCAE_5.0.owl\n",
      "8. DMDSONT.rdf\n",
      "9. EDAM.owl\n",
      "10. GAMUTS.owl\n",
      "11. ICD10CM_with_imports.rdf\n",
      "12. ICD9CM_with_imports.rdf\n",
      "13. O3_20250709.owl\n",
      "14. OBOREL.owl\n",
      "15. OMIM_with_imports.rdf\n",
      "16. RXNORM_with_imports.rdf\n",
      "17. SCO_with_imports.rdf\n",
      "18. SNMI_with_imports.rdf\n",
      "19. VANDF_with_imports.rdf\n",
      "20. bao_complete_with_imports.rdf\n",
      "21. bcio.owl\n",
      "22. bervo.owl\n",
      "23. cheminf_with_imports.rdf\n",
      "24. cl.owl\n",
      "25. clo_merged.owl\n",
      "26. cob.owl\n",
      "27. creno_with_imports.rdf\n",
      "28. dcm_with_imports.rdf\n",
      "29. doid_with_imports.rdf\n",
      "30. envo.owl\n",
      "31. gbol-ontology.ttl\n",
      "32. hspo_with_imports.rdf\n",
      "33. meo.v.1.0.ttl\n",
      "34. mwo.owl\n",
      "35. namo.owl.ttl\n",
      "36. ncro_with_imports.owl\n",
      "37. oae_merged.owl\n",
      "38. oba.owl\n",
      "39. obi.owl\n",
      "40. odfa.owl\n",
      "41. ordo_orphanet.owl\n",
      "42. pato.owl\n",
      "43. phases.owl\n",
      "44. plantso.owl\n",
      "45. sio-release.owl\n",
      "46. sleep.rdf\n",
      "47. slso.owl\n",
      "48. ssbd_v20250512.ttl\n",
      "49. tara-acupoints-inferred.rdf\n",
      "50. uberon.owl\n",
      "‚úÖ Ergebnisse gespeichert in Bio_Portal_ontology_characteristic_combos_counts_full.csv\n",
      "‚úÖ Auswertung gespeichert: Bio_Portal_ontology_characteristic_combos_counts_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>None</th>\n",
       "      <th>TransitiveProperty</th>\n",
       "      <th>SymmetricProperty</th>\n",
       "      <th>SymmetricProperty+TransitiveProperty</th>\n",
       "      <th>FunctionalProperty</th>\n",
       "      <th>AsymmetricProperty+IrreflexiveProperty</th>\n",
       "      <th>IrreflexiveProperty+SymmetricProperty</th>\n",
       "      <th>AsymmetricProperty</th>\n",
       "      <th>IrreflexiveProperty</th>\n",
       "      <th>AsymmetricProperty+InverseFunctionalProperty+IrreflexiveProperty</th>\n",
       "      <th>AsymmetricProperty+TransitiveProperty</th>\n",
       "      <th>InverseFunctionalProperty</th>\n",
       "      <th>ReflexiveProperty+TransitiveProperty</th>\n",
       "      <th>ReflexiveProperty+SymmetricProperty</th>\n",
       "      <th>FunctionalProperty+InverseFunctionalProperty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATC_with_imports.rdf</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allergidoc.rdf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMONT.owl</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BTO_with_imports.rdf</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDMOnto.owl</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file   None  TransitiveProperty  SymmetricProperty  \\\n",
       "0  ATC_with_imports.rdf   11.0                 2.0                3.0   \n",
       "1        Allergidoc.rdf    3.0                 0.0                0.0   \n",
       "2             BMONT.owl    8.0                 1.0                0.0   \n",
       "3  BTO_with_imports.rdf  146.0                 0.0                2.0   \n",
       "4           CDMOnto.owl   14.0                 0.0                0.0   \n",
       "\n",
       "   SymmetricProperty+TransitiveProperty  FunctionalProperty  \\\n",
       "0                                   1.0                 1.0   \n",
       "1                                   0.0                 0.0   \n",
       "2                                   0.0                 0.0   \n",
       "3                                   0.0                 0.0   \n",
       "4                                   0.0                 0.0   \n",
       "\n",
       "   AsymmetricProperty+IrreflexiveProperty  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                    55.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   IrreflexiveProperty+SymmetricProperty  AsymmetricProperty  \\\n",
       "0                                    0.0                 0.0   \n",
       "1                                    0.0                 0.0   \n",
       "2                                    0.0                 0.0   \n",
       "3                                    5.0                 2.0   \n",
       "4                                    0.0                 0.0   \n",
       "\n",
       "   IrreflexiveProperty  \\\n",
       "0                  0.0   \n",
       "1                  0.0   \n",
       "2                  0.0   \n",
       "3                  7.0   \n",
       "4                  0.0   \n",
       "\n",
       "   AsymmetricProperty+InverseFunctionalProperty+IrreflexiveProperty  \\\n",
       "0                                                0.0                  \n",
       "1                                                0.0                  \n",
       "2                                                0.0                  \n",
       "3                                                2.0                  \n",
       "4                                                0.0                  \n",
       "\n",
       "   AsymmetricProperty+TransitiveProperty  InverseFunctionalProperty  \\\n",
       "0                                    0.0                        0.0   \n",
       "1                                    0.0                        0.0   \n",
       "2                                    0.0                        0.0   \n",
       "3                                    0.0                        0.0   \n",
       "4                                    0.0                        0.0   \n",
       "\n",
       "   ReflexiveProperty+TransitiveProperty  ReflexiveProperty+SymmetricProperty  \\\n",
       "0                                   0.0                                  0.0   \n",
       "1                                   0.0                                  0.0   \n",
       "2                                   0.0                                  0.0   \n",
       "3                                   0.0                                  0.0   \n",
       "4                                   0.0                                  0.0   \n",
       "\n",
       "   FunctionalProperty+InverseFunctionalProperty  \n",
       "0                                           0.0  \n",
       "1                                           0.0  \n",
       "2                                           0.0  \n",
       "3                                           0.0  \n",
       "4                                           0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Property Eigenschaften Kombis\n",
    "# Ordner mit Ontologien\n",
    "ONT_DIR = r\"C:\\Users\\ilove\\OneDrive\\Uni\\Master - Philipps Uni\\Master Thesis\\Ontologien\\Zum Testen von Verteilungen von Konzepten\\Bio Portal\"\n",
    "OUT_CSV = \"Bio_Portal_ontology_characteristic_combos_counts_full.csv\"\n",
    "OUT_SUMMARY = \"Bio_Portal_ontology_characteristic_combos_counts_summary.csv\"\n",
    "\n",
    "EXTS = (\".owl\", \".ttl\", \".rdf\", \".jsonld\", \".nt\", \".n3\")\n",
    "\n",
    "# Property-Eigenschaften\n",
    "PROP_CHARACTERISTICS = {\n",
    "    \"TransitiveProperty\": OWL.TransitiveProperty,\n",
    "    \"FunctionalProperty\": OWL.FunctionalProperty,\n",
    "    \"SymmetricProperty\": OWL.SymmetricProperty,\n",
    "    \"InverseFunctionalProperty\": OWL.InverseFunctionalProperty,\n",
    "    \"IrreflexiveProperty\": OWL.IrreflexiveProperty,\n",
    "    \"AsymmetricProperty\": OWL.AsymmetricProperty,\n",
    "    \"ReflexiveProperty\": OWL.ReflexiveProperty,\n",
    "}\n",
    "\n",
    "rows = []\n",
    "idx = 1\n",
    "for fname in sorted(os.listdir(ONT_DIR)):\n",
    "    if not fname.lower().endswith(EXTS):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(ONT_DIR, fname)\n",
    "    print(f\"{idx}. {fname}\")\n",
    "    idx += 1\n",
    "\n",
    "    try:\n",
    "        g = Graph()\n",
    "        g.parse(path)\n",
    "    except Exception as e:\n",
    "        print(f\"   Fehler beim Parsen: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Z√§hler f√ºr diese Ontologie\n",
    "    combo_counts = {}\n",
    "\n",
    "    for prop in g.subjects(RDF.type, OWL.ObjectProperty):\n",
    "        characs = []\n",
    "        for name, owl_type in PROP_CHARACTERISTICS.items():\n",
    "            if (prop, RDF.type, owl_type) in g:\n",
    "                characs.append(name)\n",
    "\n",
    "        if characs:\n",
    "            combo = \"+\".join(sorted(characs))\n",
    "        else:\n",
    "            combo = \"None\"  # keine Eigenschaft\n",
    "\n",
    "        combo_counts[combo] = combo_counts.get(combo, 0) + 1\n",
    "\n",
    "    # Ergebniszeile f√ºr diese Ontologie\n",
    "    row = {\"file\": fname}\n",
    "    row.update(combo_counts)\n",
    "    rows.append(row)\n",
    "\n",
    "# DataFrame bauen\n",
    "df = pd.DataFrame(rows).fillna(0).set_index(\"file\")\n",
    "\n",
    "# CSV speichern\n",
    "df.to_csv(OUT_CSV)\n",
    "print(f\"‚úÖ Ergebnisse gespeichert in {OUT_CSV}\")\n",
    "\n",
    "df = pd.read_csv(OUT_CSV)\n",
    "N = len(df)\n",
    "\n",
    "# Alle Konstruktspalten f√ºr die Auswertung:\n",
    "# (Alles au√üer Datei-Name, _error und SUMME; Property-Typen bleiben drin ‚Äì werden aber nicht zusammengez√§hlt,\n",
    "#  hier machen wir eine per-Konstrukt-Auswertung, also d√ºrfen sie erscheinen.)\n",
    "construct_cols = [c for c in df.columns if c not in (\"file\", \"_error\", \"SUMME\")]\n",
    "\n",
    "summary_rows = []\n",
    "for col in construct_cols:\n",
    "    vals = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "    total = int(vals.sum())\n",
    "    ont_count = int((vals > 0).sum())\n",
    "    percent = (ont_count / N * 100) if N else 0\n",
    "\n",
    "    nonzero_vals = sorted(vals[vals > 0].tolist())\n",
    "    if ont_count > 0:\n",
    "        avg = float(vals[vals > 0].mean())\n",
    "        med = float(vals[vals > 0].median())\n",
    "        minv = min(nonzero_vals)\n",
    "        avg_0 = float(vals[vals >= 0].mean())\n",
    "        med_0 = float(vals[vals >= 0].median())\n",
    "    else:\n",
    "        avg = med = minv = avg_0 = med_0 = 0.0\n",
    "        \n",
    "    maxv = int(vals.max()) if len(vals) else 0\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"Construct\": col,\n",
    "        \"Summe\": total,\n",
    "        \"#Ontologien\": ont_count,\n",
    "        \"%Ontologien\": round(percent, 1),\n",
    "        \"√ò pro Ontologie (ohne 0)\": round(avg, 2),\n",
    "        \"√ò pro Ontologie (mit 0)\": round(avg_0, 2),\n",
    "        \"Median (ohne 0)\": med,\n",
    "        \"Median (mit 0)\": med_0,\n",
    "        \"Min (>0)\": minv,\n",
    "        \"Max\": maxv,\n",
    "        \"Werte (f√ºr Median ohne 0)\": nonzero_vals,  # hier alle Werte explizit\n",
    "        \"Werte (f√ºr Median mit 0)\": sorted(vals.tolist())\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(by=[\"Summe\", \"#Ontologien\"], ascending=False)\n",
    "summary_df.to_csv(OUT_SUMMARY, index=False)\n",
    "\n",
    "print(f\"‚úÖ Auswertung gespeichert: {OUT_SUMMARY}\")\n",
    "summary_df\n",
    "\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
